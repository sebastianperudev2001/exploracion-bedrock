{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. AI21 Labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction-following LLMs for any language task including question answering, summarization, text generation, and more\n",
    "\n",
    "- Jurassic-2 Ultra: Text\n",
    "- Jurassic-2 Mid: Text\n",
    "\n",
    "[Documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-jurassic2.html)\n",
    "\n",
    "[Pricing](https://aws.amazon.com/bedrock/pricing/)\n",
    "\n",
    "## Inference Paramaters\n",
    "\n",
    "- temperature: The lower the value the lower the randomness in the response\n",
    "- topP: The lower the value to ignore less probable options\n",
    "\n",
    "## Length\n",
    "\n",
    "- maxTokens: Maximum number of tokens to use in generated answer\n",
    "- stopSequences: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurassic-2 Ultra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jurassic-2 Ultra is AI21â€™s most powerful model for complex tasks that require advanced text generation and comprehension. Popular use cases include question answering, summarization, long-form copy generation, advanced information extraction, and more.\n",
    "\n",
    "### API Request:\n",
    "```json\n",
    "{\n",
    "  \"modelId\": \"ai21.j2-ultra-v1\",\n",
    "  \"contentType\": \"application/json\",\n",
    "  \"accept\": \"application/json\",\n",
    "  \"body\": \"{\\\"prompt\\\":\\\"this is where you place your input text\\\",\\\"maxTokens\\\":400,\\\"temperature\\\":0.9,\\\"topP\\\":0.9,\\\"stopSequences\\\":[],\\\"countPenalty\\\":{\\\"scale\\\":0},\\\"presencePenalty\\\":{\\\"scale\\\":0},\\\"frequencyPenalty\\\":{\\\"scale\\\":0}}\"\n",
    "}\n",
    "```\n",
    "\n",
    "| Criteria | Data |\n",
    "|-----------------|-----------------|\n",
    "| Supported use cases | Open book question answering, Summarization, Draft generation, Information extraction,Ideation| \n",
    "| Model attributes | Text, Classification, Insert/edit| \n",
    "| Model version | v1 | \n",
    "| Max tokens | 8191 | \n",
    "| Model version | English, Spanish, French, German, Portuguese, Italian, Dutch| \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stanford has one of the most generous financial aid programs in the country. \n",
      "\n",
      "1. Apply for financial aid. \n",
      "2. Apply for scholarships. \n",
      "3. Apply for grants. \n",
      "4. Apply for loans. \n",
      "5. Apply for fellowships. \n",
      "6. Apply for assistantships. \n",
      "7. Apply for research assistantships. \n",
      "8. Apply for teaching assistantships. \n",
      "9. Apply for research assistantships. \n",
      "10. Apply for teaching assistantships. \n",
      "11. Apply for research assistantships. \n",
      "12. Apply for teaching assistantships. \n",
      "13. Apply for research assistantships. \n",
      "14. Apply for teaching assistantships. \n",
      "15. Apply for research assistantships. \n",
      "16. Apply for teaching assistantships. \n",
      "17. Apply for research assistantships. \n",
      "18. Apply for teaching assistantships. \n",
      "19. Apply for research assistantships. \n",
      "20.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "brt = boto3.Session(profile_name=\"sebas\").client(service_name='bedrock-runtime')\n",
    "\n",
    "prompt = \"How to get a scholarship at Stanford?\"\n",
    "body = json.dumps({\n",
    "    \"prompt\": prompt, \n",
    "    \"maxTokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.5\n",
    "})\n",
    "\n",
    "modelId = 'ai21.j2-ultra-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = brt.invoke_model(\n",
    "    body=body, \n",
    "    modelId=modelId, \n",
    "    accept=accept, \n",
    "    contentType=contentType\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('completions')[0].get('data').get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurassic-2 Mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jurassic-2 Mid is less powerful than Ultra, yet carefully designed to strike the right balance between exceptional quality and affordability. Jurassic-2 Mid can be applied to any language comprehension or generation task including question answering, summarization, long-form copy generation, advanced information extraction and many others.\n",
    "\n",
    "### API Request:\n",
    "```json\n",
    "{\n",
    "  \"modelId\": \"ai21.j2-mid-v1\",\n",
    "  \"contentType\": \"application/json\",\n",
    "  \"accept\": \"application/json\",\n",
    "  \"body\": \"{\\\"prompt\\\":\\\"this is where you place your input text\\\",\\\"maxTokens\\\":200,\\\"temperature\\\":0.8,\\\"topP\\\":0.9,\\\"stopSequences\\\":[],\\\"countPenalty\\\":{\\\"scale\\\":0},\\\"presencePenalty\\\":{\\\"scale\\\":0},\\\"frequencyPenalty\\\":{\\\"scale\\\":0}}\"\n",
    "}\n",
    "```\n",
    "\n",
    "| Criteria | Data |\n",
    "|-----------------|-----------------|\n",
    "| Supported use cases | Open book question answering, Summarization, Draft generation, Information extraction,Ideation| \n",
    "| Model attributes | Text, Classification, Insert/edit, Math| \n",
    "| Model version | v1 | \n",
    "| Max tokens | 8191 | \n",
    "| Model version | English, Spanish, French, German, Portuguese, Italian, Dutch| \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stanford is one of the most difficult universities to gain admission into, and scholarships are highly competitive. However, there are a few things you can do to increase your chances of being awarded a scholarship:\n",
      "\n",
      "1. Apply early: Stanford offers early action and early decision applications, and students who apply by these deadlines are often given priority for scholarships.\n",
      "2. Write a well-crafted essay: Your essay is an important part of your application, and it should be well-written and showcase your unique qualities and accomplishments.\n",
      "3. Highlight your extracurricular activities: Stanford values students who are involved in extracurricular activities, so it's important to highlight any leadership roles or significant contributions you've made.\n",
      "4. Seek out scholarships: Stanford offers a wide range of scholarships, and it's important to seek out and apply for these early.\n",
      "5. Network: Talk to alumni or current students to learn more about Stanford and their experiences.\n",
      "\n",
      "Overall, it's important to be proactive and showcase your unique qualities and accomplishments in your application.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "brt = boto3.Session(profile_name=\"sebas\").client(service_name='bedrock-runtime')\n",
    "\n",
    "prompt = \"How to get a scholarship at Stanford?\"\n",
    "body = json.dumps({\n",
    "    \"prompt\": prompt, \n",
    "    \"maxTokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.5\n",
    "})\n",
    "\n",
    "modelId = 'ai21.j2-mid-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = brt.invoke_model(\n",
    "    body=body, \n",
    "    modelId=modelId, \n",
    "    accept=accept, \n",
    "    contentType=contentType\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('completions')[0].get('data').get('text'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
