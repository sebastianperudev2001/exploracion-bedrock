{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A121 Labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction-following LLMs for any language task including question answering, summarization, text generation, and more\n",
    "\n",
    "- Jurassic-2 Ultra: Text\n",
    "- Jurassic-2 Mid: Text\n",
    "\n",
    "[Documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-jurassic2.html)\n",
    "\n",
    "[Pricing](https://aws.amazon.com/bedrock/pricing/)\n",
    "\n",
    "## Inference Paramaters\n",
    "\n",
    "- temperature: The lower the value the lower the randomness in the response\n",
    "- topP: The lower the value to ignore less probable options\n",
    "\n",
    "## Length\n",
    "\n",
    "- maxTokens: Maximum number of tokens to use in generated answer\n",
    "- stopSequences: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurassic-2 Ultra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jurassic-2 Ultra is AI21â€™s most powerful model for complex tasks that require advanced text generation and comprehension. Popular use cases include question answering, summarization, long-form copy generation, advanced information extraction, and more.\n",
    "\n",
    "### API Request:\n",
    "```json\n",
    "{\n",
    "  \"modelId\": \"ai21.j2-ultra-v1\",\n",
    "  \"contentType\": \"application/json\",\n",
    "  \"accept\": \"application/json\",\n",
    "  \"body\": \"{\\\"prompt\\\":\\\"this is where you place your input text\\\",\\\"maxTokens\\\":400,\\\"temperature\\\":0.9,\\\"topP\\\":0.9,\\\"stopSequences\\\":[],\\\"countPenalty\\\":{\\\"scale\\\":0},\\\"presencePenalty\\\":{\\\"scale\\\":0},\\\"frequencyPenalty\\\":{\\\"scale\\\":0}}\"\n",
    "}\n",
    "```\n",
    "\n",
    "| Criteria | Data |\n",
    "|-----------------|-----------------|\n",
    "| Supported use cases | Open book question answering, Summarization, Draft generation, Information extraction,Ideation| \n",
    "| Model attributes | Text, Classification, Insert/edit| \n",
    "| Model version | v1 | \n",
    "| Max tokens | 8191 | \n",
    "| Model version | English, Spanish, French, German, Portuguese, Italian, Dutch| \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stanford is one of the most competitive universities in the world. \n",
      "\n",
      "1. First, you need to apply to Stanford. \n",
      "2. Second, you need to apply to scholarships. \n",
      "3. Third, you need to apply to financial aid. \n",
      "4. Fourth, you need to apply to loans. \n",
      "5. Fifth, you need to apply to work-study. \n",
      "6. Sixth, you need to apply to grants. \n",
      "7. Seventh, you need to apply to fellowships. \n",
      "8. Eighth, you need to apply to internships. \n",
      "9. Ninth, you need to apply to jobs. \n",
      "10. Tenth, you need to apply to fellowships. \n",
      "11. Eleventh, you need to apply to internships. \n",
      "12. Twelfth, you need to apply to jobs. \n",
      "13. Thirteenth, you need to apply to fellowships. \n",
      "14. Fourteenth, you need to apply to internships. \n",
      "15. Fifteenth, you need to apply to jobs. \n",
      "16. Sixteenth, you need to apply to fellowships. \n",
      "17. Seventeenth, you need to apply to internships\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "brt = boto3.Session(profile_name=\"sebas\").client(service_name='bedrock-runtime')\n",
    "\n",
    "prompt = \"How to get a scholarship at Stanford?\"\n",
    "body = json.dumps({\n",
    "    \"prompt\": prompt, \n",
    "    \"maxTokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.5\n",
    "})\n",
    "\n",
    "modelId = 'ai21.j2-ultra-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = brt.invoke_model(\n",
    "    body=body, \n",
    "    modelId=modelId, \n",
    "    accept=accept, \n",
    "    contentType=contentType\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('completions')[0].get('data').get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurassic-2 Mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jurassic-2 Mid is less powerful than Ultra, yet carefully designed to strike the right balance between exceptional quality and affordability. Jurassic-2 Mid can be applied to any language comprehension or generation task including question answering, summarization, long-form copy generation, advanced information extraction and many others.\n",
    "\n",
    "### API Request:\n",
    "```json\n",
    "{\n",
    "  \"modelId\": \"ai21.j2-mid-v1\",\n",
    "  \"contentType\": \"application/json\",\n",
    "  \"accept\": \"application/json\",\n",
    "  \"body\": \"{\\\"prompt\\\":\\\"this is where you place your input text\\\",\\\"maxTokens\\\":200,\\\"temperature\\\":0.8,\\\"topP\\\":0.9,\\\"stopSequences\\\":[],\\\"countPenalty\\\":{\\\"scale\\\":0},\\\"presencePenalty\\\":{\\\"scale\\\":0},\\\"frequencyPenalty\\\":{\\\"scale\\\":0}}\"\n",
    "}\n",
    "```\n",
    "\n",
    "| Criteria | Data |\n",
    "|-----------------|-----------------|\n",
    "| Supported use cases | Open book question answering, Summarization, Draft generation, Information extraction,Ideation| \n",
    "| Model attributes | Text, Classification, Insert/edit, Math| \n",
    "| Model version | v1 | \n",
    "| Max tokens | 8191 | \n",
    "| Model version | English, Spanish, French, German, Portuguese, Italian, Dutch| \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stanford is one of the most difficult universities to gain admission into, and scholarships are highly competitive. However, there are a few things you can do to increase your chances of being awarded a scholarship:\n",
      "\n",
      "1. Apply early: Stanford offers early action and early decision applications, and students who apply by these deadlines are often given priority for scholarships.\n",
      "2. Write a well-crafted essay: Your essay is an important part of your application, and it should be well-written and showcase your unique qualities and accomplishments.\n",
      "3. Highlight your extracurricular activities: Stanford values students who are involved in extracurricular activities, so it's important to highlight any leadership roles or significant contributions you've made.\n",
      "4. Seek out scholarships: Stanford offers a wide range of scholarships, and it's important to seek out and apply for these early.\n",
      "5. Network: Talk to alumni or current students to learn more about Stanford and their experiences.\n",
      "\n",
      "Overall, it's important to be proactive and showcase your unique qualities and accomplishments in your application.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "brt = boto3.Session(profile_name=\"sebas\").client(service_name='bedrock-runtime')\n",
    "\n",
    "prompt = \"How to get a scholarship at Stanford?\"\n",
    "body = json.dumps({\n",
    "    \"prompt\": prompt, \n",
    "    \"maxTokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.5\n",
    "})\n",
    "\n",
    "modelId = 'ai21.j2-mid-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = brt.invoke_model(\n",
    "    body=body, \n",
    "    modelId=modelId, \n",
    "    accept=accept, \n",
    "    contentType=contentType\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('completions')[0].get('data').get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titan Embeddings G1 - Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titan Text G1 - Lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titan Text G1 Express"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titan Image Generator G1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titan multimodal Embeddings G1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Anthropic \n",
    "No tengo acceso a esto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed multilingual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 2 Chat 13B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 2 Chat 70B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tengo acceso a Llama 2 13B ni Llama 2 70B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Stability AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDXL 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDXL 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
